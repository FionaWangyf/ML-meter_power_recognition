import cv2
import os
import glob
# import numpy as np
import random
import shutil
from pathlib import Path
import yaml
import csv
from datetime import datetime

# ===============================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå›¾åƒæ ‡æ³¨å·¥å…·
# ===============================================

class MeterAnnotationTool:
    def __init__(self, image_folder):
        """
        ç”µè¡¨è¯»æ•°åŒºåŸŸæ ‡æ³¨å·¥å…·

        Args:
            image_folder: åŒ…å«ç°åº¦ç”µè¡¨å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
        """
        self.image_folder = image_folder
        self.annotations_folder = "annotations"
        self.current_image = None
        self.current_image_path = ""
        self.image_list = []
        self.current_index = 0
        self.bbox_list = []
        self.drawing = False
        self.start_point = (-1, -1)
        self.end_point = (-1, -1)
        self.temp_image = None

        # åˆ›å»ºæ ‡æ³¨æ–‡ä»¶å¤¹
        os.makedirs(self.annotations_folder, exist_ok=True)

        # åŠ è½½å›¾ç‰‡åˆ—è¡¨
        self.load_image_list()

        # ç±»åˆ«ä¿¡æ¯
        self.class_names = ["meter_display"]
        self.current_class = 0

    def load_image_list(self):
        """åŠ è½½å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨"""
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        for ext in extensions:
            self.image_list.extend(glob.glob(os.path.join(self.image_folder, ext)))
            self.image_list.extend(glob.glob(os.path.join(self.image_folder, ext.upper())))

        if not self.image_list:
            print(f"é”™è¯¯ï¼šåœ¨æ–‡ä»¶å¤¹ {self.image_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶!")
            return

        self.image_list.sort()
        print(f"æ‰¾åˆ° {len(self.image_list)} å¼ å›¾ç‰‡å¾…æ ‡æ³¨")

    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡å›è°ƒå‡½æ•°"""
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
            self.start_point = (x, y)

        elif event == cv2.EVENT_MOUSEMOVE:
            if self.drawing:
                self.temp_image = self.current_image.copy()
                cv2.rectangle(self.temp_image, self.start_point, (x, y), (0, 255, 0), 2)

        elif event == cv2.EVENT_LBUTTONUP:
            self.drawing = False
            self.end_point = (x, y)

            # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡®
            x1 = min(self.start_point[0], self.end_point[0])
            y1 = min(self.start_point[1], self.end_point[1])
            x2 = max(self.start_point[0], self.end_point[0])
            y2 = max(self.start_point[1], self.end_point[1])

            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦æœ‰æ•ˆ
            if abs(x2 - x1) > 10 and abs(y2 - y1) > 10:
                self.bbox_list.append([x1, y1, x2, y2, self.current_class])
                print(f"æ·»åŠ è¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")

            self.draw_bboxes()

    def draw_bboxes(self):
        """ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œæ¡†"""
        self.current_image = cv2.imread(self.current_image_path)

        for bbox in self.bbox_list:
            x1, y1, x2, y2, class_id = bbox
            cv2.rectangle(self.current_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(self.current_image, self.class_names[class_id],
                        (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    def convert_to_yolo_format(self, bbox, img_width, img_height):
        """è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        x1, y1, x2, y2, class_id = bbox

        center_x = (x1 + x2) / 2.0
        center_y = (y1 + y2) / 2.0
        width = x2 - x1
        height = y2 - y1

        # å½’ä¸€åŒ–
        center_x /= img_width
        center_y /= img_height
        width /= img_width
        height /= img_height

        return class_id, center_x, center_y, width, height

    def save_annotations(self):
        """ä¿å­˜æ ‡æ³¨"""
        if not self.bbox_list:
            print("å½“å‰å›¾ç‰‡æ²¡æœ‰æ ‡æ³¨")
            return

        img = cv2.imread(self.current_image_path)
        img_height, img_width = img.shape[:2]

        image_name = Path(self.current_image_path).stem
        label_file = os.path.join(self.annotations_folder, f"{image_name}.txt")

        with open(label_file, 'w') as f:
            for bbox in self.bbox_list:
                class_id, center_x, center_y, width, height = self.convert_to_yolo_format(
                    bbox, img_width, img_height)
                f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")

        print(f"ä¿å­˜: {label_file}")

    def load_existing_annotations(self):
        """åŠ è½½å·²æœ‰æ ‡æ³¨"""
        image_name = Path(self.current_image_path).stem
        label_file = os.path.join(self.annotations_folder, f"{image_name}.txt")

        self.bbox_list = []

        if os.path.exists(label_file):
            img = cv2.imread(self.current_image_path)
            img_height, img_width = img.shape[:2]

            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id = int(parts[0])
                        center_x = float(parts[1]) * img_width
                        center_y = float(parts[2]) * img_height
                        width = float(parts[3]) * img_width
                        height = float(parts[4]) * img_height

                        x1 = int(center_x - width / 2)
                        y1 = int(center_y - height / 2)
                        x2 = int(center_x + width / 2)
                        y2 = int(center_y + height / 2)

                        self.bbox_list.append([x1, y1, x2, y2, class_id])

    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
        ========== ç”µè¡¨è¯»æ•°åŒºåŸŸæ ‡æ³¨å·¥å…· ==========

        æ“ä½œè¯´æ˜:
        ğŸ–±ï¸  é¼ æ ‡å·¦é”®æ‹–æ‹½: ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆæ¡†é€‰æ•°å­—æ˜¾ç¤ºåŒºåŸŸï¼‰
        ğŸ’¾ 's' é”®: ä¿å­˜å½“å‰å›¾ç‰‡çš„æ ‡æ³¨
        â¡ï¸  'n' é”®: ä¸‹ä¸€å¼ å›¾ç‰‡
        â¬…ï¸  'p' é”®: ä¸Šä¸€å¼ å›¾ç‰‡
        ğŸ—‘ï¸  'c' é”®: æ¸…é™¤å½“å‰å›¾ç‰‡çš„æ‰€æœ‰æ ‡æ³¨
        âŒ 'd' é”®: åˆ é™¤æœ€åä¸€ä¸ªæ ‡æ³¨
        â“ 'h' é”®: æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        ğŸšª 'q' é”®: é€€å‡ºç¨‹åº

        æ ‡æ³¨æç¤º:
        ğŸ“ è¯·å‡†ç¡®æ¡†é€‰ç”µè¡¨æ•°å­—æ˜¾ç¤ºåŒºåŸŸ
        ğŸ“ è¾¹ç•Œæ¡†åº”è¯¥ç´§è´´æ•°å­—è¾¹ç¼˜
        ğŸ”¢ å¯ä»¥æ ‡æ³¨å¤šä¸ªæ•°å­—åŒºåŸŸ

        ==========================================
        """
        print(help_text)

    def run(self):
        """è¿è¡Œæ ‡æ³¨å·¥å…·"""
        if not self.image_list:
            return

        self.show_help()

        cv2.namedWindow('ç”µè¡¨æ ‡æ³¨å·¥å…·', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('ç”µè¡¨æ ‡æ³¨å·¥å…·', 1200, 800)
        cv2.setMouseCallback('ç”µè¡¨æ ‡æ³¨å·¥å…·', self.mouse_callback)

        # åŠ è½½ç¬¬ä¸€å¼ å›¾ç‰‡
        self.current_image_path = self.image_list[self.current_index]
        self.load_existing_annotations()
        self.draw_bboxes()

        while True:
            # æ˜¾ç¤ºä¿¡æ¯
            info = f"å›¾ç‰‡ {self.current_index + 1}/{len(self.image_list)} | " \
                   f"æ ‡æ³¨: {len(self.bbox_list)} ä¸ª | " \
                   f"æ–‡ä»¶: {os.path.basename(self.current_image_path)}"

            display_img = self.current_image.copy() if self.temp_image is None else self.temp_image.copy()
            cv2.putText(display_img, info, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

            cv2.imshow('ç”µè¡¨æ ‡æ³¨å·¥å…·', display_img)

            key = cv2.waitKey(1) & 0xFF

            if key == ord('q'):
                break
            elif key == ord('s'):
                self.save_annotations()
            elif key == ord('n'):
                if self.current_index < len(self.image_list) - 1:
                    self.current_index += 1
                    self.current_image_path = self.image_list[self.current_index]
                    self.load_existing_annotations()
                    self.draw_bboxes()
                    self.temp_image = None
            elif key == ord('p'):
                if self.current_index > 0:
                    self.current_index -= 1
                    self.current_image_path = self.image_list[self.current_index]
                    self.load_existing_annotations()
                    self.draw_bboxes()
                    self.temp_image = None
            elif key == ord('c'):
                self.bbox_list = []
                self.draw_bboxes()
                print("æ¸…é™¤æ‰€æœ‰æ ‡æ³¨")
            elif key == ord('d'):
                if self.bbox_list:
                    self.bbox_list.pop()
                    self.draw_bboxes()
                    print("åˆ é™¤æœ€åä¸€ä¸ªæ ‡æ³¨")
            elif key == ord('h'):
                self.show_help()

        cv2.destroyAllWindows()


# ===============================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é›†å‡†å¤‡
# ===============================================

def prepare_dataset(images_folder, annotations_folder, output_folder="dataset", train_ratio=0.8):
    """å‡†å¤‡YOLOè®­ç»ƒæ•°æ®é›†"""

    print("ğŸ“ å‡†å¤‡YOLOæ•°æ®é›†...")

    # åˆ›å»ºç›®å½•ç»“æ„
    dirs = ['images/train', 'images/val', 'labels/train', 'labels/val']
    for dir_path in dirs:
        os.makedirs(os.path.join(output_folder, dir_path), exist_ok=True)

    # è·å–å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶å¯¹
    image_files = []
    label_files = []

    for img_path in Path(images_folder).glob('*'):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
            label_path = Path(annotations_folder) / f"{img_path.stem}.txt"
            if label_path.exists():
                image_files.append(img_path)
                label_files.append(label_path)

    if not image_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡-æ ‡æ³¨å¯¹ï¼")
        return False

    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¯¹å›¾ç‰‡-æ ‡æ³¨æ–‡ä»¶")

    # éšæœºæ‰“ä¹±å¹¶åˆ†å‰²
    combined = list(zip(image_files, label_files))
    random.shuffle(combined)

    train_count = int(len(combined) * train_ratio)
    train_data = combined[:train_count]
    val_data = combined[train_count:]

    print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_data)} å¼ ")
    print(f"ğŸ“Š éªŒè¯é›†: {len(val_data)} å¼ ")

    # å¤åˆ¶æ–‡ä»¶
    def copy_data(data_list, split):
        for img_path, label_path in data_list:
            # å¤åˆ¶å›¾ç‰‡
            dst_img = os.path.join(output_folder, 'images', split, img_path.name)
            shutil.copy2(img_path, dst_img)

            # å¤åˆ¶æ ‡æ³¨
            dst_label = os.path.join(output_folder, 'labels', split, label_path.name)
            shutil.copy2(label_path, dst_label)

    copy_data(train_data, 'train')
    copy_data(val_data, 'val')

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config = {
        'train': 'images/train',
        'val': 'images/val',
        'nc': 1,
        'names': ['meter_display']
    }

    config_path = os.path.join(output_folder, 'dataset.yaml')
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

    print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ: {output_folder}")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")

    return True


# ===============================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹è®­ç»ƒ
# ===============================================

def install_requirements():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    print("ğŸ“¦ æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…...")

    requirements = [
        "ultralytics",
        "opencv-python",
        "PyYAML",
        "torch",
        "torchvision"
    ]

    install_commands = []
    for package in requirements:
        install_commands.append(f"pip install {package}")

    print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
    for cmd in install_commands:
        print(f"  {cmd}")

    print("\næˆ–è€…ä¸€æ¬¡æ€§å®‰è£…:")
    print(f"  pip install {' '.join(requirements)}")


def train_yolo_model(dataset_folder="dataset", epochs=100, img_size=640, batch_size=16):
    """è®­ç»ƒYOLOæ¨¡å‹"""

    try:
        from ultralytics import YOLO
    except ImportError:
        print("âŒ æœªå®‰è£…ultralyticsï¼Œè¯·å…ˆå®‰è£…ä¾èµ–")
        install_requirements()
        return False

    print("ğŸš€ å¼€å§‹è®­ç»ƒYOLOæ¨¡å‹...")

    # æ£€æŸ¥æ•°æ®é›†é…ç½®æ–‡ä»¶
    config_path = os.path.join(dataset_folder, 'dataset.yaml')
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨YOLOv8 nanoæ¨¡å‹

    # è®­ç»ƒå‚æ•°
    train_args = {
        'data': config_path,
        'epochs': epochs,
        'imgsz': img_size,
        'batch': batch_size,
        'name': 'meter_detection',
        'save': True,
        'save_period': 10,
        'val': True,
        'plots': True,
        'device': 'auto'  # è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
    }

    print("ğŸ”§ è®­ç»ƒå‚æ•°:")
    for key, value in train_args.items():
        print(f"  {key}: {value}")

    try:
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_args)

        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: runs/detect/meter_detection/weights/")
        print(f"ğŸ“Š æœ€ä½³æ¨¡å‹: runs/detect/meter_detection/weights/best.pt")

        return True

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False


# ===============================================
# ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹æµ‹è¯•ï¼ˆåªå–æœ€é«˜ç½®ä¿¡åº¦ç»“æœï¼‰
# ===============================================

def test_model(model_path="runs/detect/meter_detection/weights/best.pt", test_images_folder="processed_images"):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹ - åªä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ"""

    try:
        from ultralytics import YOLO
    except ImportError:
        print("âŒ æœªå®‰è£…ultralytics")
        return

    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    print(f"ğŸ” åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)

    # è·å–æµ‹è¯•å›¾ç‰‡
    test_images = []
    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
    for ext in extensions:
        test_images.extend(glob.glob(os.path.join(test_images_folder, ext)))
        test_images.extend(glob.glob(os.path.join(test_images_folder, ext.upper())))

    if not test_images:
        print(f"âŒ åœ¨ {test_images_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return

    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")

    # åˆ›å»ºç»“æœæ–‡ä»¶å¤¹
    results_folder = "detection_results"
    os.makedirs(results_folder, exist_ok=True)

    # å‡†å¤‡CSVæ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = os.path.join(results_folder, f"detection_results_best_{timestamp}.csv")

    # CSVæ•°æ®å­˜å‚¨åˆ—è¡¨
    csv_data = []

    # æ·»åŠ CSVè¡¨å¤´
    csv_headers = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class_name', 'total_detections']

    # è¾“å‡ºè¡¨å¤´åˆ°æ§åˆ¶å°
    print("\næ£€æµ‹ç»“æœ (ä»…æ˜¾ç¤ºæœ€é«˜ç½®ä¿¡åº¦):")
    print("filename\t\txmin\tymin\txmax\tymax\tconfidence\ttotal_det")
    print("-" * 80)

    # ç»Ÿè®¡å˜é‡
    total_images_with_detection = 0
    total_images_with_multiple_detection = 0
    processed_count = 0

    # é¢„æµ‹å¹¶ä¿å­˜ç»“æœ
    for img_path in test_images:  # æµ‹è¯•æ‰€æœ‰å›¾ç‰‡
        filename = os.path.basename(img_path)
        print(f"å¤„ç† ({processed_count + 1}/{len(test_images)}): {filename}")

        try:
            results = model(img_path)

            # å¤„ç†æ£€æµ‹ç»“æœ
            best_detection = None
            total_detections_count = 0

            for i, result in enumerate(results):
                if result.boxes is not None and len(result.boxes) > 0:
                    # è·å–æ£€æµ‹æ¡†åæ ‡ã€ç½®ä¿¡åº¦å’Œç±»åˆ«
                    boxes = result.boxes.xyxy.cpu().numpy()  # åæ ‡
                    confidences = result.boxes.conf.cpu().numpy()  # ç½®ä¿¡åº¦
                    classes = result.boxes.cls.cpu().numpy()  # ç±»åˆ«

                    total_detections_count = len(boxes)

                    if total_detections_count > 0:
                        total_images_with_detection += 1

                        if total_detections_count > 1:
                            total_images_with_multiple_detection += 1

                        # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ
                        best_idx = confidences.argmax()  # è·å–ç½®ä¿¡åº¦æœ€é«˜çš„ç´¢å¼•

                        best_box = boxes[best_idx]
                        best_confidence = confidences[best_idx]
                        best_class_id = int(classes[best_idx])
                        best_class_name = model.names[best_class_id] if best_class_id in model.names else 'unknown'

                        xmin, ymin, xmax, ymax = best_box[:4]

                        best_detection = {
                            'filename': filename,
                            'xmin': int(xmin),
                            'ymin': int(ymin),
                            'xmax': int(xmax),
                            'ymax': int(ymax),
                            'confidence': best_confidence,
                            'class_name': best_class_name,
                            'total_detections': total_detections_count
                        }

                # ä¿å­˜å¯è§†åŒ–ç»“æœå›¾ç‰‡ï¼ˆæ˜¾ç¤ºæœ€ä½³æ£€æµ‹ï¼‰
                if best_detection:
                    result_img = result.plot()  # è¿™ä¼šæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹ç»“æœ

                    # åˆ›å»ºåªæ˜¾ç¤ºæœ€ä½³æ£€æµ‹çš„å›¾ç‰‡
                    original_img = cv2.imread(img_path)
                    cv2.rectangle(original_img,
                                  (best_detection['xmin'], best_detection['ymin']),
                                  (best_detection['xmax'], best_detection['ymax']),
                                  (0, 255, 0), 3)  # ç»¿è‰²ç²—çº¿æ¡†

                    # æ·»åŠ æ ‡ç­¾
                    label = f"BEST: {best_detection['class_name']} {best_detection['confidence']:.3f}"
                    cv2.putText(original_img, label,
                                (best_detection['xmin'], best_detection['ymin'] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    # æ·»åŠ æ€»æ£€æµ‹æ•°ä¿¡æ¯
                    info_text = f"Total detections: {total_detections_count}"
                    cv2.putText(original_img, info_text,
                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

                    # ä¿å­˜æœ€ä½³æ£€æµ‹ç»“æœå›¾ç‰‡
                    result_path = os.path.join(results_folder, f"best_{filename}")
                    cv2.imwrite(result_path, original_img)

            # æ·»åŠ åˆ°CSVæ•°æ®å’Œæ§åˆ¶å°è¾“å‡º
            if best_detection:
                csv_data.append([
                    best_detection['filename'],
                    best_detection['xmin'],
                    best_detection['ymin'],
                    best_detection['xmax'],
                    best_detection['ymax'],
                    f"{best_detection['confidence']:.4f}",
                    best_detection['class_name'],
                    best_detection['total_detections']
                ])

                # è¾“å‡ºåˆ°æ§åˆ¶å°
                print(f"{filename}\t\t{best_detection['xmin']}\t{best_detection['ymin']}\t"
                      f"{best_detection['xmax']}\t{best_detection['ymax']}\t"
                      f"{best_detection['confidence']:.4f}\t\t{total_detections_count}")

                # å¦‚æœæœ‰å¤šä¸ªæ£€æµ‹ï¼Œæ˜¾ç¤ºæç¤º
                if total_detections_count > 1:
                    print(f"  â””â”€ æ³¨æ„: å…±æ£€æµ‹åˆ° {total_detections_count} ä¸ªç›®æ ‡ï¼Œå·²é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„")
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡çš„æƒ…å†µ
                csv_data.append([
                    filename,
                    '',
                    '',
                    '',
                    '',
                    '',
                    'no_detection',
                    0
                ])
                print(f"{filename}\t\tæœªæ£€æµ‹åˆ°ç›®æ ‡")

        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡ {filename} æ—¶å‡ºé”™: {e}")
            # è®°å½•é”™è¯¯åˆ°CSV
            csv_data.append([
                filename,
                '',
                '',
                '',
                '',
                '',
                'error',
                0
            ])

        processed_count += 1

    # å†™å…¥CSVæ–‡ä»¶
    try:
        with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(csv_headers)  # å†™å…¥è¡¨å¤´
            writer.writerows(csv_data)  # å†™å…¥æ•°æ®

        print(f"\nâœ… CSVç»“æœå·²ä¿å­˜: {csv_filename}")
    except Exception as e:
        print(f"âŒ ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")

    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
    print(f"  æ€»å›¾ç‰‡æ•°: {len(test_images)}")
    print(f"  å¤„ç†æˆåŠŸ: {processed_count}")
    print(f"  æœ‰æ£€æµ‹ç»“æœ: {total_images_with_detection}")
    print(
        f"  æ£€æµ‹æˆåŠŸç‡: {(total_images_with_detection / processed_count) * 100:.2f}%" if processed_count > 0 else "  æ£€æµ‹æˆåŠŸç‡: 0%")
    print(f"  å¤šç›®æ ‡æ£€æµ‹å›¾ç‰‡: {total_images_with_multiple_detection}")
    print(
        f"  å¤šç›®æ ‡ç‡: {(total_images_with_multiple_detection / max(total_images_with_detection, 1)) * 100:.2f}%" if total_images_with_detection > 0 else "  å¤šç›®æ ‡ç‡: 0%")
    print(f"ğŸ“ æœ€ä½³æ£€æµ‹ç»“æœå›¾ç‰‡ä¿å­˜åœ¨: {results_folder}/best_*.jpg")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœä¿å­˜åœ¨: {csv_filename}")


def analyze_detection_results(csv_file_path):
    """åˆ†ææ£€æµ‹ç»“æœçš„ç»Ÿè®¡ä¿¡æ¯"""

    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return

    print(f"ğŸ“Š åˆ†ææ£€æµ‹ç»“æœ: {csv_file_path}")

    try:
        with open(csv_file_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            rows = list(reader)

        # åŸºæœ¬ç»Ÿè®¡
        total_images = len(rows)
        successful_detections = [row for row in rows if row['class_name'] not in ['no_detection', 'error', '']]
        no_detection_count = len([row for row in rows if row['class_name'] == 'no_detection'])
        error_count = len([row for row in rows if row['class_name'] == 'error'])

        # å¤šæ£€æµ‹ç»Ÿè®¡
        multi_detection_images = [row for row in rows if row['total_detections'] and int(row['total_detections']) > 1]

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = []
        for row in successful_detections:
            if row['confidence']:
                try:
                    confidences.append(float(row['confidence']))
                except ValueError:
                    pass

        print(f"\nğŸ“ˆ æ£€æµ‹ç»“æœç»Ÿè®¡:")
        print(f"  æ€»å›¾ç‰‡æ•°: {total_images}")
        print(f"  æˆåŠŸæ£€æµ‹æ•°: {len(successful_detections)}")
        print(f"  æœªæ£€æµ‹åˆ°: {no_detection_count}")
        print(f"  å¤„ç†é”™è¯¯: {error_count}")
        print(
            f"  æ£€æµ‹æˆåŠŸç‡: {(len(successful_detections) / total_images) * 100:.2f}%" if total_images > 0 else "  æ£€æµ‹æˆåŠŸç‡: 0%")

        # å¤šæ£€æµ‹åˆ†æ
        print(f"\nğŸ” å¤šæ£€æµ‹åˆ†æ:")
        print(f"  æœ‰å¤šä¸ªæ£€æµ‹çš„å›¾ç‰‡: {len(multi_detection_images)}")
        print(
            f"  å¤šæ£€æµ‹ç‡: {(len(multi_detection_images) / len(successful_detections)) * 100:.2f}%" if successful_detections else "  å¤šæ£€æµ‹ç‡: 0%")

        if multi_detection_images:
            detection_counts = [int(row['total_detections']) for row in multi_detection_images]
            print(f"  æœ€å¤šæ£€æµ‹æ•°: {max(detection_counts)}")
            print(f"  å¹³å‡æ£€æµ‹æ•°: {sum(detection_counts) / len(detection_counts):.2f}")

        # ç½®ä¿¡åº¦åˆ†æ
        if confidences:
            print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†æ:")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {sum(confidences) / len(confidences):.4f}")
            print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max(confidences):.4f}")
            print(f"  æœ€ä½ç½®ä¿¡åº¦: {min(confidences):.4f}")

            # ç½®ä¿¡åº¦åˆ†å¸ƒ
            high_conf = len([c for c in confidences if c >= 0.8])
            medium_conf = len([c for c in confidences if 0.5 <= c < 0.8])
            low_conf = len([c for c in confidences if c < 0.5])

            print(f"\nğŸ“Š ç½®ä¿¡åº¦åˆ†å¸ƒ:")
            print(f"  é«˜ç½®ä¿¡åº¦ (â‰¥0.8): {high_conf} ({high_conf / len(confidences) * 100:.1f}%)")
            print(f"  ä¸­ç½®ä¿¡åº¦ (0.5-0.8): {medium_conf} ({medium_conf / len(confidences) * 100:.1f}%)")
            print(f"  ä½ç½®ä¿¡åº¦ (<0.5): {low_conf} ({low_conf / len(confidences) * 100:.1f}%)")

    except Exception as e:
        print(f"âŒ åˆ†æCSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")


def show_multi_detection_samples(csv_file_path, top_n=10):
    """æ˜¾ç¤ºå¤šæ£€æµ‹æ ·æœ¬"""

    if not os.path.exists(csv_file_path):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return

    try:
        with open(csv_file_path, 'r', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            rows = list(reader)

        # æ‰¾å‡ºå¤šæ£€æµ‹çš„å›¾ç‰‡ï¼ŒæŒ‰æ£€æµ‹æ•°é‡æ’åº
        multi_detection_rows = [row for row in rows if row['total_detections'] and int(row['total_detections']) > 1]
        multi_detection_rows.sort(key=lambda x: int(x['total_detections']), reverse=True)

        print(f"\nğŸ” å¤šæ£€æµ‹æ ·æœ¬ (å‰{min(top_n, len(multi_detection_rows))}ä¸ª):")
        print("-" * 100)

        for i, row in enumerate(multi_detection_rows[:top_n]):
            print(f"{i + 1:2d}. {row['filename']} - æ£€æµ‹æ•°: {row['total_detections']}, "
                  f"æœ€ä½³ç½®ä¿¡åº¦: {row['confidence']}, "
                  f"åæ ‡: ({row['xmin']},{row['ymin']})-({row['xmax']},{row['ymax']})")

        if multi_detection_rows:
            print(f"\nğŸ’¡ å»ºè®®æŸ¥çœ‹è¿™äº›å›¾ç‰‡çš„ best_*.jpg ç»“æœæ–‡ä»¶ï¼Œç¡®è®¤æ£€æµ‹è´¨é‡")

    except Exception as e:
        print(f"âŒ æ˜¾ç¤ºå¤šæ£€æµ‹æ ·æœ¬æ—¶å‡ºé”™: {e}")

# æ›´æ–°ä¸»ç¨‹åºä¸­çš„é€‰æ‹©é¡¹
def main():
    """ä¸»ç¨‹åºå…¥å£ - æ›´æ–°ç‰ˆæœ¬"""

    print("=" * 60)
    print("ğŸ”¬ ç”µè¡¨è¯»æ•°åŒºåŸŸæ£€æµ‹å®Œæ•´æµç¨‹")
    print("=" * 60)

    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å¤¹
    images_folder = "processed_images"
    if not os.path.exists(images_folder):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ '{images_folder}' ä¸å­˜åœ¨!")
        print("è¯·ç¡®ä¿å°†ç°åº¦ç”µè¡¨å›¾ç‰‡æ”¾åœ¨è¯¥æ–‡ä»¶å¤¹ä¸­")
        return

    while True:
        print("\nğŸ”§ é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“ æ ‡æ³¨å›¾ç‰‡ (åˆ›å»ºè®­ç»ƒæ ‡ç­¾)")
        print("2. ğŸ“ å‡†å¤‡æ•°æ®é›† (æ•´ç†ä¸ºYOLOæ ¼å¼)")
        print("3. ğŸš€ è®­ç»ƒæ¨¡å‹")
        print("4. ğŸ” æµ‹è¯•æ¨¡å‹ (ç”ŸæˆCSVç»“æœ)")
        print("5. ğŸ“Š åˆ†ææ£€æµ‹ç»“æœ")
        print("6. ğŸ“¦ å®‰è£…ä¾èµ–")
        print("0. ğŸšª é€€å‡º")

        choice = input("\nè¯·é€‰æ‹© (0-6): ").strip()

        if choice == '1':
            print("\nğŸ“ å¯åŠ¨å›¾ç‰‡æ ‡æ³¨å·¥å…·...")
            annotator = MeterAnnotationTool(images_folder)
            annotator.run()

        elif choice == '2':
            print("\nğŸ“ å‡†å¤‡æ•°æ®é›†...")
            success = prepare_dataset(images_folder, "annotations")
            if success:
                print("âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ!")

        elif choice == '3':
            print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            epochs = input("è®­ç»ƒè½®æ•° (é»˜è®¤100): ").strip()
            epochs = int(epochs) if epochs.isdigit() else 100

            success = train_yolo_model(epochs=epochs)
            if success:
                print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")

        elif choice == '4':
            print("\nğŸ” æµ‹è¯•æ¨¡å‹...")
            model_path = input("æ¨¡å‹è·¯å¾„ (é»˜è®¤: runs/detect/meter_detection/weights/best.pt): ").strip()
            if not model_path:
                model_path = "runs/detect/meter_detection/weights/best.pt"
            test_model(model_path)

        elif choice == '5':
            print("\nğŸ“Š åˆ†ææ£€æµ‹ç»“æœ...")
            csv_files = glob.glob("detection_results/detection_results_*.csv")
            if csv_files:
                print("æ‰¾åˆ°çš„CSVæ–‡ä»¶:")
                for i, file in enumerate(csv_files, 1):
                    print(f"  {i}. {os.path.basename(file)}")

                choice_csv = input(f"é€‰æ‹©æ–‡ä»¶ (1-{len(csv_files)}) æˆ–è¾“å…¥å®Œæ•´è·¯å¾„: ").strip()

                if choice_csv.isdigit() and 1 <= int(choice_csv) <= len(csv_files):
                    csv_file = csv_files[int(choice_csv) - 1]
                else:
                    csv_file = choice_csv

                analyze_detection_results(csv_file)
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æµ‹ç»“æœCSVæ–‡ä»¶")
                csv_file = input("è¯·è¾“å…¥CSVæ–‡ä»¶è·¯å¾„: ").strip()
                if csv_file:
                    analyze_detection_results(csv_file)

        elif choice == '6':
            install_requirements()

        elif choice == '0':
            print("ğŸ‘‹ å†è§!")
            break

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")


if __name__ == "__main__":
    main()