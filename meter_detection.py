import cv2
import os
import glob
# import numpy as np
import random
import shutil
from pathlib import Path
import yaml


# ===============================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šå›¾åƒæ ‡æ³¨å·¥å…·
# ===============================================

class MeterAnnotationTool:
    def __init__(self, image_folder):
        """
        ç”µè¡¨è¯»æ•°åŒºåŸŸæ ‡æ³¨å·¥å…·

        Args:
            image_folder: åŒ…å«ç°åº¦ç”µè¡¨å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
        """
        self.image_folder = image_folder
        self.annotations_folder = "annotations"
        self.current_image = None
        self.current_image_path = ""
        self.image_list = []
        self.current_index = 0
        self.bbox_list = []
        self.drawing = False
        self.start_point = (-1, -1)
        self.end_point = (-1, -1)
        self.temp_image = None

        # åˆ›å»ºæ ‡æ³¨æ–‡ä»¶å¤¹
        os.makedirs(self.annotations_folder, exist_ok=True)

        # åŠ è½½å›¾ç‰‡åˆ—è¡¨
        self.load_image_list()

        # ç±»åˆ«ä¿¡æ¯
        self.class_names = ["meter_display"]
        self.current_class = 0

    def load_image_list(self):
        """åŠ è½½å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨"""
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        for ext in extensions:
            self.image_list.extend(glob.glob(os.path.join(self.image_folder, ext)))
            self.image_list.extend(glob.glob(os.path.join(self.image_folder, ext.upper())))

        if not self.image_list:
            print(f"é”™è¯¯ï¼šåœ¨æ–‡ä»¶å¤¹ {self.image_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶!")
            return

        self.image_list.sort()
        print(f"æ‰¾åˆ° {len(self.image_list)} å¼ å›¾ç‰‡å¾…æ ‡æ³¨")

    def mouse_callback(self, event, x, y, flags, param):
        """é¼ æ ‡å›è°ƒå‡½æ•°"""
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
            self.start_point = (x, y)

        elif event == cv2.EVENT_MOUSEMOVE:
            if self.drawing:
                self.temp_image = self.current_image.copy()
                cv2.rectangle(self.temp_image, self.start_point, (x, y), (0, 255, 0), 2)

        elif event == cv2.EVENT_LBUTTONUP:
            self.drawing = False
            self.end_point = (x, y)

            # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡®
            x1 = min(self.start_point[0], self.end_point[0])
            y1 = min(self.start_point[1], self.end_point[1])
            x2 = max(self.start_point[0], self.end_point[0])
            y2 = max(self.start_point[1], self.end_point[1])

            # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦æœ‰æ•ˆ
            if abs(x2 - x1) > 10 and abs(y2 - y1) > 10:
                self.bbox_list.append([x1, y1, x2, y2, self.current_class])
                print(f"æ·»åŠ è¾¹ç•Œæ¡†: ({x1}, {y1}, {x2}, {y2})")

            self.draw_bboxes()

    def draw_bboxes(self):
        """ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œæ¡†"""
        self.current_image = cv2.imread(self.current_image_path)

        for bbox in self.bbox_list:
            x1, y1, x2, y2, class_id = bbox
            cv2.rectangle(self.current_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(self.current_image, self.class_names[class_id],
                        (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    def convert_to_yolo_format(self, bbox, img_width, img_height):
        """è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        x1, y1, x2, y2, class_id = bbox

        center_x = (x1 + x2) / 2.0
        center_y = (y1 + y2) / 2.0
        width = x2 - x1
        height = y2 - y1

        # å½’ä¸€åŒ–
        center_x /= img_width
        center_y /= img_height
        width /= img_width
        height /= img_height

        return class_id, center_x, center_y, width, height

    def save_annotations(self):
        """ä¿å­˜æ ‡æ³¨"""
        if not self.bbox_list:
            print("å½“å‰å›¾ç‰‡æ²¡æœ‰æ ‡æ³¨")
            return

        img = cv2.imread(self.current_image_path)
        img_height, img_width = img.shape[:2]

        image_name = Path(self.current_image_path).stem
        label_file = os.path.join(self.annotations_folder, f"{image_name}.txt")

        with open(label_file, 'w') as f:
            for bbox in self.bbox_list:
                class_id, center_x, center_y, width, height = self.convert_to_yolo_format(
                    bbox, img_width, img_height)
                f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")

        print(f"ä¿å­˜: {label_file}")

    def load_existing_annotations(self):
        """åŠ è½½å·²æœ‰æ ‡æ³¨"""
        image_name = Path(self.current_image_path).stem
        label_file = os.path.join(self.annotations_folder, f"{image_name}.txt")

        self.bbox_list = []

        if os.path.exists(label_file):
            img = cv2.imread(self.current_image_path)
            img_height, img_width = img.shape[:2]

            with open(label_file, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id = int(parts[0])
                        center_x = float(parts[1]) * img_width
                        center_y = float(parts[2]) * img_height
                        width = float(parts[3]) * img_width
                        height = float(parts[4]) * img_height

                        x1 = int(center_x - width / 2)
                        y1 = int(center_y - height / 2)
                        x2 = int(center_x + width / 2)
                        y2 = int(center_y + height / 2)

                        self.bbox_list.append([x1, y1, x2, y2, class_id])

    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
        ========== ç”µè¡¨è¯»æ•°åŒºåŸŸæ ‡æ³¨å·¥å…· ==========

        æ“ä½œè¯´æ˜:
        ğŸ–±ï¸  é¼ æ ‡å·¦é”®æ‹–æ‹½: ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆæ¡†é€‰æ•°å­—æ˜¾ç¤ºåŒºåŸŸï¼‰
        ğŸ’¾ 's' é”®: ä¿å­˜å½“å‰å›¾ç‰‡çš„æ ‡æ³¨
        â¡ï¸  'n' é”®: ä¸‹ä¸€å¼ å›¾ç‰‡
        â¬…ï¸  'p' é”®: ä¸Šä¸€å¼ å›¾ç‰‡
        ğŸ—‘ï¸  'c' é”®: æ¸…é™¤å½“å‰å›¾ç‰‡çš„æ‰€æœ‰æ ‡æ³¨
        âŒ 'd' é”®: åˆ é™¤æœ€åä¸€ä¸ªæ ‡æ³¨
        â“ 'h' é”®: æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        ğŸšª 'q' é”®: é€€å‡ºç¨‹åº

        æ ‡æ³¨æç¤º:
        ğŸ“ è¯·å‡†ç¡®æ¡†é€‰ç”µè¡¨æ•°å­—æ˜¾ç¤ºåŒºåŸŸ
        ğŸ“ è¾¹ç•Œæ¡†åº”è¯¥ç´§è´´æ•°å­—è¾¹ç¼˜
        ğŸ”¢ å¯ä»¥æ ‡æ³¨å¤šä¸ªæ•°å­—åŒºåŸŸ

        ==========================================
        """
        print(help_text)

    def run(self):
        """è¿è¡Œæ ‡æ³¨å·¥å…·"""
        if not self.image_list:
            return

        self.show_help()

        cv2.namedWindow('ç”µè¡¨æ ‡æ³¨å·¥å…·', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('ç”µè¡¨æ ‡æ³¨å·¥å…·', 1200, 800)
        cv2.setMouseCallback('ç”µè¡¨æ ‡æ³¨å·¥å…·', self.mouse_callback)

        # åŠ è½½ç¬¬ä¸€å¼ å›¾ç‰‡
        self.current_image_path = self.image_list[self.current_index]
        self.load_existing_annotations()
        self.draw_bboxes()

        while True:
            # æ˜¾ç¤ºä¿¡æ¯
            info = f"å›¾ç‰‡ {self.current_index + 1}/{len(self.image_list)} | " \
                   f"æ ‡æ³¨: {len(self.bbox_list)} ä¸ª | " \
                   f"æ–‡ä»¶: {os.path.basename(self.current_image_path)}"

            display_img = self.current_image.copy() if self.temp_image is None else self.temp_image.copy()
            cv2.putText(display_img, info, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

            cv2.imshow('ç”µè¡¨æ ‡æ³¨å·¥å…·', display_img)

            key = cv2.waitKey(1) & 0xFF

            if key == ord('q'):
                break
            elif key == ord('s'):
                self.save_annotations()
            elif key == ord('n'):
                if self.current_index < len(self.image_list) - 1:
                    self.current_index += 1
                    self.current_image_path = self.image_list[self.current_index]
                    self.load_existing_annotations()
                    self.draw_bboxes()
                    self.temp_image = None
            elif key == ord('p'):
                if self.current_index > 0:
                    self.current_index -= 1
                    self.current_image_path = self.image_list[self.current_index]
                    self.load_existing_annotations()
                    self.draw_bboxes()
                    self.temp_image = None
            elif key == ord('c'):
                self.bbox_list = []
                self.draw_bboxes()
                print("æ¸…é™¤æ‰€æœ‰æ ‡æ³¨")
            elif key == ord('d'):
                if self.bbox_list:
                    self.bbox_list.pop()
                    self.draw_bboxes()
                    print("åˆ é™¤æœ€åä¸€ä¸ªæ ‡æ³¨")
            elif key == ord('h'):
                self.show_help()

        cv2.destroyAllWindows()


# ===============================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®é›†å‡†å¤‡
# ===============================================

def prepare_dataset(images_folder, annotations_folder, output_folder="dataset", train_ratio=0.8):
    """å‡†å¤‡YOLOè®­ç»ƒæ•°æ®é›†"""

    print("ğŸ“ å‡†å¤‡YOLOæ•°æ®é›†...")

    # åˆ›å»ºç›®å½•ç»“æ„
    dirs = ['images/train', 'images/val', 'labels/train', 'labels/val']
    for dir_path in dirs:
        os.makedirs(os.path.join(output_folder, dir_path), exist_ok=True)

    # è·å–å›¾ç‰‡å’Œæ ‡æ³¨æ–‡ä»¶å¯¹
    image_files = []
    label_files = []

    for img_path in Path(images_folder).glob('*'):
        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
            label_path = Path(annotations_folder) / f"{img_path.stem}.txt"
            if label_path.exists():
                image_files.append(img_path)
                label_files.append(label_path)

    if not image_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡-æ ‡æ³¨å¯¹ï¼")
        return False

    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¯¹å›¾ç‰‡-æ ‡æ³¨æ–‡ä»¶")

    # éšæœºæ‰“ä¹±å¹¶åˆ†å‰²
    combined = list(zip(image_files, label_files))
    random.shuffle(combined)

    train_count = int(len(combined) * train_ratio)
    train_data = combined[:train_count]
    val_data = combined[train_count:]

    print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_data)} å¼ ")
    print(f"ğŸ“Š éªŒè¯é›†: {len(val_data)} å¼ ")

    # å¤åˆ¶æ–‡ä»¶
    def copy_data(data_list, split):
        for img_path, label_path in data_list:
            # å¤åˆ¶å›¾ç‰‡
            dst_img = os.path.join(output_folder, 'images', split, img_path.name)
            shutil.copy2(img_path, dst_img)

            # å¤åˆ¶æ ‡æ³¨
            dst_label = os.path.join(output_folder, 'labels', split, label_path.name)
            shutil.copy2(label_path, dst_label)

    copy_data(train_data, 'train')
    copy_data(val_data, 'val')

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config = {
        'train': 'images/train',
        'val': 'images/val',
        'nc': 1,
        'names': ['meter_display']
    }

    config_path = os.path.join(output_folder, 'dataset.yaml')
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)

    print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ: {output_folder}")
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")

    return True


# ===============================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ¨¡å‹è®­ç»ƒ
# ===============================================

def install_requirements():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    print("ğŸ“¦ æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…...")

    requirements = [
        "ultralytics",
        "opencv-python",
        "PyYAML",
        "torch",
        "torchvision"
    ]

    install_commands = []
    for package in requirements:
        install_commands.append(f"pip install {package}")

    print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
    for cmd in install_commands:
        print(f"  {cmd}")

    print("\næˆ–è€…ä¸€æ¬¡æ€§å®‰è£…:")
    print(f"  pip install {' '.join(requirements)}")


def train_yolo_model(dataset_folder="dataset", epochs=100, img_size=640, batch_size=16):
    """è®­ç»ƒYOLOæ¨¡å‹"""

    try:
        from ultralytics import YOLO
    except ImportError:
        print("âŒ æœªå®‰è£…ultralyticsï¼Œè¯·å…ˆå®‰è£…ä¾èµ–")
        install_requirements()
        return False

    print("ğŸš€ å¼€å§‹è®­ç»ƒYOLOæ¨¡å‹...")

    # æ£€æŸ¥æ•°æ®é›†é…ç½®æ–‡ä»¶
    config_path = os.path.join(dataset_folder, 'dataset.yaml')
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False

    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨YOLOv8 nanoæ¨¡å‹

    # è®­ç»ƒå‚æ•°
    train_args = {
        'data': config_path,
        'epochs': epochs,
        'imgsz': img_size,
        'batch': batch_size,
        'name': 'meter_detection',
        'save': True,
        'save_period': 10,
        'val': True,
        'plots': True,
        'device': 'auto'  # è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
    }

    print("ğŸ”§ è®­ç»ƒå‚æ•°:")
    for key, value in train_args.items():
        print(f"  {key}: {value}")

    try:
        # å¼€å§‹è®­ç»ƒ
        results = model.train(**train_args)

        print("âœ… è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: runs/detect/meter_detection/weights/")
        print(f"ğŸ“Š æœ€ä½³æ¨¡å‹: runs/detect/meter_detection/weights/best.pt")

        return True

    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False


# ===============================================
# ç¬¬å››éƒ¨åˆ†ï¼šæ¨¡å‹æµ‹è¯•
# ===============================================

def test_model(model_path="runs/detect/meter_detection/weights/best.pt", test_images_folder="processed_images"):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""

    try:
        from ultralytics import YOLO
    except ImportError:
        print("âŒ æœªå®‰è£…ultralytics")
        return

    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    print(f"ğŸ” åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)

    # è·å–æµ‹è¯•å›¾ç‰‡
    test_images = []
    for ext in ['*.jpg', '*.jpeg', '*.png']:
        test_images.extend(glob.glob(os.path.join(test_images_folder, ext)))

    if not test_images:
        print(f"âŒ åœ¨ {test_images_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
        return

    print(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")

    # åˆ›å»ºç»“æœæ–‡ä»¶å¤¹
    results_folder = "detection_results"
    os.makedirs(results_folder, exist_ok=True)

    # è¾“å‡ºè¡¨å¤´
    print("\næ£€æµ‹ç»“æœ:")
    print("filename\t\txmin\tymin\txmax\tymax")
    print("-" * 50)

    # é¢„æµ‹å¹¶ä¿å­˜ç»“æœ
    for img_path in test_images[:50]:  # åªæµ‹è¯•å‰50å¼ 
        print(f"å¤„ç†: {os.path.basename(img_path)}")

        results = model(img_path)

        # ä¿å­˜ç»“æœå›¾ç‰‡
        for i, result in enumerate(results):
            result_img = result.plot()
            result_path = os.path.join(results_folder, f"result_{os.path.basename(img_path)}")
            cv2.imwrite(result_path, result_img)

            # è¾“å‡ºæ£€æµ‹æ¡†ä½ç½®ä¿¡æ¯
            filename = os.path.basename(img_path)

            if result.boxes is not None and len(result.boxes) > 0:
                # è·å–æ£€æµ‹æ¡†åæ ‡
                boxes = result.boxes.xyxy.cpu().numpy()  # è½¬æ¢ä¸ºnumpyæ•°ç»„

                for box in boxes:
                    xmin, ymin, xmax, ymax = box[:4]
                    print(f"{filename}\t\t{int(xmin)}\t{int(ymin)}\t{int(xmax)}\t{int(ymax)}")
            else:
                print(f"{filename}\t\tæœªæ£€æµ‹åˆ°ç›®æ ‡")

    print(f"\nâœ… æ£€æµ‹ç»“æœä¿å­˜åœ¨: {results_folder}")


# ===============================================
# ä¸»ç¨‹åº
# ===============================================

def main():
    """ä¸»ç¨‹åºå…¥å£"""

    print("=" * 60)
    print("ğŸ”¬ ç”µè¡¨è¯»æ•°åŒºåŸŸæ£€æµ‹å®Œæ•´æµç¨‹")
    print("=" * 60)

    # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å¤¹
    images_folder = "processed_images"
    if not os.path.exists(images_folder):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ '{images_folder}' ä¸å­˜åœ¨!")
        print("è¯·ç¡®ä¿å°†ç°åº¦ç”µè¡¨å›¾ç‰‡æ”¾åœ¨è¯¥æ–‡ä»¶å¤¹ä¸­")
        return

    while True:
        print("\nğŸ”§ é€‰æ‹©æ“ä½œ:")
        print("1. ğŸ“ æ ‡æ³¨å›¾ç‰‡ (åˆ›å»ºè®­ç»ƒæ ‡ç­¾)")
        print("2. ğŸ“ å‡†å¤‡æ•°æ®é›† (æ•´ç†ä¸ºYOLOæ ¼å¼)")
        print("3. ğŸš€ è®­ç»ƒæ¨¡å‹")
        print("4. ğŸ” æµ‹è¯•æ¨¡å‹")
        print("5. ğŸ“¦ å®‰è£…ä¾èµ–")
        print("0. ğŸšª é€€å‡º")

        choice = input("\nè¯·é€‰æ‹© (0-5): ").strip()

        if choice == '1':
            print("\nğŸ“ å¯åŠ¨å›¾ç‰‡æ ‡æ³¨å·¥å…·...")
            annotator = MeterAnnotationTool(images_folder)
            annotator.run()

        elif choice == '2':
            print("\nğŸ“ å‡†å¤‡æ•°æ®é›†...")
            success = prepare_dataset(images_folder, "annotations")
            if success:
                print("âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ!")

        elif choice == '3':
            print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            epochs = input("è®­ç»ƒè½®æ•° (é»˜è®¤100): ").strip()
            epochs = int(epochs) if epochs.isdigit() else 100

            success = train_yolo_model(epochs=epochs)
            if success:
                print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")

        elif choice == '4':
            print("\nğŸ” æµ‹è¯•æ¨¡å‹...")
            model_path = input("æ¨¡å‹è·¯å¾„ (é»˜è®¤: runs/detect/meter_detection/weights/best.pt): ").strip()
            if not model_path:
                model_path = "runs/detect/meter_detection/weights/best.pt"
            test_model(model_path)

        elif choice == '5':
            install_requirements()

        elif choice == '0':
            print("ğŸ‘‹ å†è§!")
            break

        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")


if __name__ == "__main__":
    main()